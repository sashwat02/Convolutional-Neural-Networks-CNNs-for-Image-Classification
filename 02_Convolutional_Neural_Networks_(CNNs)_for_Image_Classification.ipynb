{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt8XTjvmsE6j"
      },
      "source": [
        "### REQURIED LIB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDyeOU_MsE6m"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA (GPU) is available, otherwise use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "1DHA_US_Zgez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "XRI6ETCS71KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing and Loading Dataset"
      ],
      "metadata": {
        "id": "6ymx4W7Q7ske"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transformations for the images\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load the MNIST dataset and create data loaders\n",
        "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "CHKRnxwEZm2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CI0fqsqccEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zS2LITDSVlad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "JUtA755ncPg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Data\n",
        "Let's visualize a few examples from the dataset to understand the input images better."
      ],
      "metadata": {
        "id": "cwU0dCWv4Wnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape"
      ],
      "metadata": {
        "id": "6K3sY1-pU9Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to display a grid of images\n",
        "def show_images(images, labels, nrows, ncols):\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(np.squeeze(images[i]), cmap='gray')\n",
        "        ax.set_title(f\"Label: {labels[i]}\")\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images and labels from the test dataset\n",
        "images, labels = next(iter(test_dataloader))\n",
        "\n",
        "# Display the images and their labels\n",
        "show_images(images, labels, 4, 8)"
      ],
      "metadata": {
        "id": "Eg4-yFP7axtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img , label = train_dataset[0]\n",
        "plt.imshow(np.squeeze(img), cmap='gray')"
      ],
      "metadata": {
        "id": "IUQ1ZSj2bGjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtel1hdLsE6q"
      },
      "source": [
        "## Model Architecture\n",
        "Next, we'll define our CNN model architecture using PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfaMQIIrsE6q"
      },
      "outputs": [],
      "source": [
        "#CNN model architecture using PyTorch framework\n",
        "class DigitClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3)\n",
        "        self.L1 = nn.Linear(in_features=8*5*5, out_features=64)\n",
        "        self.L2 = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # 1*28*28 --> 16*24*24\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.flatten(start_dim=1, end_dim=-1)\n",
        "        x = F.relu(self.L1(x))\n",
        "        x = F.relu(self.L2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2C-xqwrsE6r"
      },
      "source": [
        "#Training the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss Function and Optimizer\n",
        "We need to specify the loss function and optimizer for training the model."
      ],
      "metadata": {
        "id": "Wki5r4h_5Be4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-hY5K28sE6r"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model and move it to the appropriate device\n",
        "model = DigitClassification().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01,)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop\n",
        "Now, we'll implement the training loop to train our model on the MNIST dataset."
      ],
      "metadata": {
        "id": "R4Mu6J0s5JZv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqXAMPyAsE6r"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        data, label = batch[0].to(device), batch[1].to(device)  # Move data to device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predicted = model(data)\n",
        "        loss = criterion(predicted, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted_labels = torch.max(predicted, 1)\n",
        "        correct += (predicted_labels == label).sum().item()\n",
        "        total += label.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return total_loss / len(train_dataloader), accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUC-JfRzsE6r"
      },
      "source": [
        "### TEST loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwb_dWeLsE6s"
      },
      "outputs": [],
      "source": [
        "def test(model, test_dataloader, criterion, optimizer):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients during testing\n",
        "        for batch in test_dataloader:\n",
        "            data, label = batch[0].to(device), batch[1].to(device)  # Move data to device\n",
        "\n",
        "            predicted = model(data)\n",
        "            loss = criterion(predicted, label)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted_labels = torch.max(predicted, 1)\n",
        "            correct += (predicted_labels == label).sum().item()\n",
        "            total += label.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return total_loss / len(test_dataloader), accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the model for a certain number of epochs\n",
        "num_epochs = 30\n",
        "training_losses = []\n",
        "testing_losses = []\n",
        "training_accuracies = []\n",
        "testing_accuracies = []"
      ],
      "metadata": {
        "id": "gJdk4tRwahQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOjCJ3ZhsE6s"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(num_epochs), desc='Training Progress'):\n",
        "\n",
        "    training_loss, training_accuracy = train(model, train_dataloader, criterion, optimizer)\n",
        "    testing_loss, testing_accuracy = test(model, test_dataloader, criterion, optimizer)\n",
        "\n",
        "    # Append losses and accuracies for visualization\n",
        "    training_losses.append(training_loss)\n",
        "    testing_losses.append(testing_loss)\n",
        "    training_accuracies.append(training_accuracy)\n",
        "    testing_accuracies.append(testing_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}: Training Loss: {training_loss}, Testing Loss: {testing_loss}, Training Accuracy: {training_accuracy}, Testing Accuracy: {testing_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training and testing losses\n",
        "plt.plot(training_losses, label='Training Loss')\n",
        "plt.plot(testing_losses, label='Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j44TIgylanGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(training_accuracies, label='Training Accuracy')\n",
        "plt.plot(testing_accuracies, label='Testing Accuracy')\n",
        "plt.title('Training and Testing Accuracies')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bU0hZjT6dgM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions and Visualization\n",
        "## Making Predictions\n",
        "Let's make predictions on new data using the trained model."
      ],
      "metadata": {
        "id": "QUHwHllj56eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions on new data\n",
        "def predict(model, dataloader):\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs = data[0].to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "Anm0iy46v0BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test dataset\n",
        "test_predictions = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "jHwac8mOet2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def process_input_image(image_path):\n",
        "    # Load the image and convert to grayscale\n",
        "    img = Image.open(image_path).convert('L')\n",
        "    # Resize to 28x28 and convert to numpy array\n",
        "    img = img.resize((28, 28))\n",
        "    img_array = np.array(img)\n",
        "    # Normalize pixel values\n",
        "    img_array = img_array.astype('float32') / 255.0\n",
        "    # Add a batch dimension and return\n",
        "    return np.expand_dims(img_array, axis=0)"
      ],
      "metadata": {
        "id": "2nDNwSbS3Eiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Predictions\n",
        "We'll visualize a random sample of test images along with their predicted labels."
      ],
      "metadata": {
        "id": "xkXSgzl96Fnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot a random sample of images along with their predicted labels\n",
        "def visualize_predictions(dataset, predictions, num_samples=5):\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    samples = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    for i, idx in enumerate(samples):\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        image, label = dataset[idx]\n",
        "        plt.imshow(image.squeeze(), cmap='gray')\n",
        "        plt.title(f\"Predicted: {predictions[idx]}, Actual: {label}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TEn-_zDaezIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize predictions on a random sample of test images\n",
        "visualize_predictions(test_dataset, test_predictions)"
      ],
      "metadata": {
        "id": "2qW9KUQUe11S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQVtx2bgu427"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape the data\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(8, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "def visualize_predictions(dataset, predictions, num_samples=5):\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    samples = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    for i, idx in enumerate(samples):\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        image, label = dataset[idx]\n",
        "        plt.imshow(image.squeeze(), cmap='gray')\n",
        "        plt.title(f\"Predicted: {predictions[idx]}, Actual: {label}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "7MiJSYu5czzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-12dCPSgIl1B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}